import numpy as np
import math

training_data = [
    ['Green', 3, 'Apple'],
    ['Yellow', 3, 'Apple'],
    ['Red', 1, 'Grape'],
    ['Red', 1, 'Grape'],
    ['Yellow', 3, 'Lemon']]

header = ["color", "diameter", "label"]


def unique(rows, col):
    return set([row[col] for row in rows])


class Node:
    def __init__(self):
        self.leaf = False
        self.children = {}
        self.attr = None
        self.predicted = 0

    def is_leaf(self):
        return self.leaf

    def get_child(self, identifier):
        return self.children[identifier]

    def get_class(self,):
        return self.predicted

    def get_split_attr(self):
        assert self.is_leaf() == False

        return self.attr


class DTreeNode(Node):
    def __init__(self, idxs):
        super(DTreeNode, self).__init__()

        # There have to be some data points here!
        assert len(idxs) > 0

        self.idxs = idxs

    def get_idxs(self):
        return self.idxs

    def get_entropy(self, labels):
        size = len(labels)
        data, counts = np.unique(labels, return_counts=True)
        entropy = 0
        for i in counts:
            calculated = i/size
            if calculated > 0:
                entropy = entropy - calculated * math.log(calculated, 2)

        return entropy

    def should_stop(self, data):
        stop = True
        x = data[self.idxs, :]
        for i in range(1, x.shape[0]):
            if not np.equal(x[i-1, :], x[i, :]).all():
                stop = False
                break
        return stop

    def set_class(self, unique, counts):
        max_val = 0
        max_i = 0
        for i in range(counts.shape[0]):
            if counts[i] > max_val:
                max_i = i
        self.predicted = unique[max_i]


def _calc_information_gain(self, parent_node, children_nodes):
    parent_entropy = parent_node.get_entropy(self.labels[parent_node.get_idxs()])
    weighted_entropy = 0
    parent_size = len(parent_node.get_idxs())
    for i in children_nodes:
        child_size = len(i.get_idxs())
        child_avg = child_size/parent_size
        child_entropy = child_avg * i.get_entropy(self.labels[i.get_idxs()])
        weighted_entropy = weighted_entropy + child_entropy

    return parent_entropy - weighted_entropy


if __name__ == '__main__':

    my_tree = build_tree(training_data)

    print_tree(my_tree)

    # Evaluate
    testing_data = [
        ['Green', 3, 'Apple'],
        ['Yellow', 4, 'Apple'],
        ['Red', 2, 'Grape'],
        ['Red', 1, 'Grape'],
        ['Yellow', 3, 'Lemon'],
    ]



